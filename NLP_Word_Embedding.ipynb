{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##One Hot Encoding"
      ],
      "metadata": {
        "id": "9Gtqy7Hkdnds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4XtTPx4fZBjQ"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoding(text):\n",
        "  words = text.split()\n",
        "  vocabulary = set(words)\n",
        "  word_to_index = {word: index for index, word in enumerate(vocabulary)}\n",
        "  one_hot_encoded = []\n",
        "  for word in words:\n",
        "    one_hot_vector = [0] * len(vocabulary)\n",
        "    one_hot_vector[word_to_index[word]] = 1\n",
        "    one_hot_encoded.append(one_hot_vector)\n",
        "  return one_hot_encoded, word_to_index, vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"This is a sample text for one-hot encoding.\"\n",
        "one_hot_encoded, word_to_index, vocabulary = one_hot_encoding(sample_text)"
      ],
      "metadata": {
        "id": "qHlAPy8_eHnp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary:\", vocabulary)\n",
        "print(\"Word-to-Index Mapping:\", word_to_index)\n",
        "print(\"One-Hot Encoded Matrix:\")\n",
        "for word, encoding in zip(sample_text.split(), one_hot_encoded):\n",
        "  print(f\"{word}: {encoding}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg8-SoAJeOVU",
        "outputId": "247e154f-d39c-463f-9c9d-82c795d804c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'sample', 'text', 'a', 'This', 'encoding.', 'one-hot', 'for', 'is'}\n",
            "Word-to-Index Mapping: {'sample': 0, 'text': 1, 'a': 2, 'This': 3, 'encoding.': 4, 'one-hot': 5, 'for': 6, 'is': 7}\n",
            "One-Hot Encoded Matrix:\n",
            "This: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "is: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "a: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "sample: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "text: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "for: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "one-hot: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "encoding.: [0, 0, 0, 0, 1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bag of Words"
      ],
      "metadata": {
        "id": "YxnEISpwfVcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "documents = [\"This is the first document.\",\n",
        "\t\t\t\"This document is the second document.\",\n",
        "\t\t\t\"And this is the third one.\",\n",
        "\t\t\t\"Is this the first document?\"]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Bag-of-Words Matrix:\")\n",
        "print(X.toarray())\n",
        "print(\"Vocabulary (Feature Names):\", feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnLFa4l8e1ul",
        "outputId": "a215bb1a-ed2c-4cca-8e36-4aad1730d291"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words Matrix:\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "Vocabulary (Feature Names): ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TF-IDF"
      ],
      "metadata": {
        "id": "0yh9Hot8lkQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample\n",
        "documents = [\n",
        "\t\"The quick brown fox jumps over the lazy dog.\",\n",
        "\t\"A journey of a thousand miles begins with a single step.\",\n",
        "]"
      ],
      "metadata": {
        "id": "e8tOht63grG-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer() # Create the TF-IDF vectorizer\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "tfidf_values = {}"
      ],
      "metadata": {
        "id": "Xpg4crIals3R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc_index, doc in enumerate(documents):\n",
        "\tfeature_index = tfidf_matrix[doc_index, :].nonzero()[1]\n",
        "\ttfidf_doc_values = zip(feature_index, [tfidf_matrix[doc_index, x] for x in feature_index])\n",
        "\ttfidf_values[doc_index] = {feature_names[i]: value for i, value in tfidf_doc_values}"
      ],
      "metadata": {
        "id": "Txq1sU9Zls59"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc_index, values in tfidf_values.items():\n",
        "\tprint(f\"Document {doc_index + 1}:\")\n",
        "\tfor word, tfidf_value in values.items():\n",
        "\t\tprint(f\"{word}: {tfidf_value}\")\n",
        "\tprint(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7xnRwnQls82",
        "outputId": "5041300c-c670-44b9-ce30-c0f5c38844fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "the: 0.6030226891555273\n",
            "quick: 0.30151134457776363\n",
            "brown: 0.30151134457776363\n",
            "fox: 0.30151134457776363\n",
            "jumps: 0.30151134457776363\n",
            "over: 0.30151134457776363\n",
            "lazy: 0.30151134457776363\n",
            "dog: 0.30151134457776363\n",
            "\n",
            "\n",
            "Document 2:\n",
            "journey: 0.3535533905932738\n",
            "of: 0.3535533905932738\n",
            "thousand: 0.3535533905932738\n",
            "miles: 0.3535533905932738\n",
            "begins: 0.3535533905932738\n",
            "with: 0.3535533905932738\n",
            "single: 0.3535533905932738\n",
            "step: 0.3535533905932738\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V5kd5ydLl0Tc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}