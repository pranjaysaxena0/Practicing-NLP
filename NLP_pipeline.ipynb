{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEt5dO-tEgqz"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "NLP Pipeline\n",
        "    Sentence segmentation\n",
        "    Word tokenization\n",
        "    Stemming\n",
        "    Lemmatization\n",
        "    Stop words removal\n",
        "    POS tagging\n",
        "    Name Entity Recognition (NER)\n",
        "    Chunking\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization"
      ],
      "metadata": {
        "id": "asMHIRcJOZVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "def tokenize_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return sentences\n",
        "text = input(\"Enter the text: \")\n",
        "sentences = tokenize_sentences(text)\n",
        "# print sentences\n",
        "for i,sentence in enumerate (sentences):\n",
        "    print(f\"{i+1}. {sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-pIdUpMOHgn",
        "outputId": "edfe1167-eb3b-4a64-bbce-b195abbd6256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: One of the tell-tale signs of cheating on your Spanish homework is that grammatically, it’s a mess. Many languages don’t allow for straight translation and have different orders for sentence structure, which translation services used to overlook. But, they’ve come a long way. With NLP, online translators can translate languages more accurately and present grammatically-correct results. This is infinitely helpful when trying to communicate with someone in another language. Not only that, but when translating from another language to your own, tools now recognize the language based on inputted text and translate it.\n",
            "1. One of the tell-tale signs of cheating on your Spanish homework is that grammatically, it’s a mess.\n",
            "2. Many languages don’t allow for straight translation and have different orders for sentence structure, which translation services used to overlook.\n",
            "3. But, they’ve come a long way.\n",
            "4. With NLP, online translators can translate languages more accurately and present grammatically-correct results.\n",
            "5. This is infinitely helpful when trying to communicate with someone in another language.\n",
            "6. Not only that, but when translating from another language to your own, tools now recognize the language based on inputted text and translate it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Tokenisation"
      ],
      "metadata": {
        "id": "UH5ZZ0RoPSc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def tokenize_words(text):\n",
        "    words = word_tokenize(text)\n",
        "    return words\n",
        "#Tokenize words\n",
        "text = input(\"Enter the text: \")\n",
        "words = tokenize_words(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA_37L01PTOI",
        "outputId": "f065f18e-e44d-4528-e80c-ba3a1a3cf564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: Many languages don’t allow for straight translation and have different orders for sentence structure, which translation services used to overlook.\n",
            "['Many', 'languages', 'don', '’', 't', 'allow', 'for', 'straight', 'translation', 'and', 'have', 'different', 'orders', 'for', 'sentence', 'structure', ',', 'which', 'translation', 'services', 'used', 'to', 'overlook', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "8LqQFkecPwyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "porter = PorterStemmer()\n",
        "def stem_words(words):\n",
        "    stemmed_words = [porter.stem(word) for word in words]\n",
        "    return stemmed_words\n",
        "#Stemming words\n",
        "text = input(\"Enter the text: \")\n",
        "words = word_tokenize(text)\n",
        "stemmed_words = stem_words(words)\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eojP4zyyP0Fx",
        "outputId": "9f326a7d-c07a-4dff-bad1-d997fb045709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: This is infinitely helpful when trying to communicate with someone in another language.\n",
            "['thi', 'is', 'infinit', 'help', 'when', 'tri', 'to', 'commun', 'with', 'someon', 'in', 'anoth', 'languag', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "DvyIAZh1QUZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXGI33LhQtKr",
        "outputId": "b6c4578f-6073-4395-b53d-2be57774acec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "#tokenize text\n",
        "tokens = word_tokenize(text)\n",
        "#Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtz4zusvQVl9",
        "outputId": "aca3393c-4d59-477c-d650-80aa84ea1595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'infinitely', 'helpful', 'when', 'trying', 'to', 'communicate', 'with', 'someone', 'in', 'another', 'language', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop Words"
      ],
      "metadata": {
        "id": "tfCK32S8Q2mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ts0cUsRq2n",
        "outputId": "c56b97d0-52fe-4fb7-91a6-49192dc86760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "def remove_stopwords(text):\n",
        "    #Tokenize text into words\n",
        "    words = word_tokenize(text)\n",
        "    #get english stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    #remove stopwords\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return filtered_words\n",
        "#Remove stopwords\n",
        "text = input(\"Enter the text: \")\n",
        "print(text)\n",
        "filtered_words = remove_stopwords(text)\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LFiFLWaQ4YT",
        "outputId": "3d09b206-e166-41dc-c75f-0c0d0304f406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: With NLP, online translators can translate languages more accurately and present grammatically-correct results.\n",
            "With NLP, online translators can translate languages more accurately and present grammatically-correct results.\n",
            "['NLP', ',', 'online', 'translators', 'translate', 'languages', 'accurately', 'present', 'grammatically-correct', 'results', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS tagging"
      ],
      "metadata": {
        "id": "OorQihqrOLdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxWHbScoFEqL",
        "outputId": "373d123b-b558-4d9e-a9f7-aaf1cf18838e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pos tagging\n",
        "from nltk.tokenize import word_tokenize\n",
        "def pos_tagging(text):\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    return pos_tags"
      ],
      "metadata": {
        "id": "-EsskBgLFEsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter the text: \")\n",
        "pos_tagged_text = pos_tagging(text)\n",
        "print(pos_tagged_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo-TxtV6FYN5",
        "outputId": "303d0393-803c-4cc5-ce6c-227a0a43d885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: Natural language processing (NLP) is the science of getting computers to talk, or interact with humans in human language. Examples of natural language processing include speech recognition, spell check, autocomplete, chatbots, and search engines.\n",
            "[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('the', 'DT'), ('science', 'NN'), ('of', 'IN'), ('getting', 'VBG'), ('computers', 'NNS'), ('to', 'TO'), ('talk', 'VB'), (',', ','), ('or', 'CC'), ('interact', 'NN'), ('with', 'IN'), ('humans', 'NNS'), ('in', 'IN'), ('human', 'JJ'), ('language', 'NN'), ('.', '.'), ('Examples', 'NNS'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('include', 'VBP'), ('speech', 'JJ'), ('recognition', 'NN'), (',', ','), ('spell', 'RB'), ('check', 'VB'), (',', ','), ('autocomplete', 'VB'), (',', ','), ('chatbots', 'NNS'), (',', ','), ('and', 'CC'), ('search', 'NN'), ('engines', 'NNS'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name Entity Recognisation (NER)"
      ],
      "metadata": {
        "id": "YKDe7NITIeJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk"
      ],
      "metadata": {
        "id": "KAxSMQujGPRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Rw4v7CIvxq",
        "outputId": "d5cada8b-56aa-4d0d-ab43-21dc4155a0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ner(text):\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = pos_tag(words)\n",
        "    named_entities = ne_chunk(pos_tags)\n",
        "    return named_entities\n",
        "named_entities = ner(text)\n",
        "print(named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfIe7xL_I3IY",
        "outputId": "cb0a2c5c-2973-4f45-d734-eb8465f50fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  Natural/JJ\n",
            "  language/NN\n",
            "  processing/NN\n",
            "  (/(\n",
            "  (ORGANIZATION NLP/NNP)\n",
            "  )/)\n",
            "  is/VBZ\n",
            "  the/DT\n",
            "  science/NN\n",
            "  of/IN\n",
            "  getting/VBG\n",
            "  computers/NNS\n",
            "  to/TO\n",
            "  talk/VB\n",
            "  ,/,\n",
            "  or/CC\n",
            "  interact/NN\n",
            "  with/IN\n",
            "  humans/NNS\n",
            "  in/IN\n",
            "  human/JJ\n",
            "  language/NN\n",
            "  ./.\n",
            "  Examples/NNS\n",
            "  of/IN\n",
            "  natural/JJ\n",
            "  language/NN\n",
            "  processing/NN\n",
            "  include/VBP\n",
            "  speech/JJ\n",
            "  recognition/NN\n",
            "  ,/,\n",
            "  spell/RB\n",
            "  check/VB\n",
            "  ,/,\n",
            "  autocomplete/VB\n",
            "  ,/,\n",
            "  chatbots/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  search/NN\n",
            "  engines/NNS\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking"
      ],
      "metadata": {
        "id": "Qa_dlJMAJuUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "#Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "#POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "#Chunking patterns\n",
        "chunk_patterns = r\"\"\"\n",
        "    NP: {<DT>?<JJ>*<NN>}\n",
        "    VP: {<VB.*><NP|PP>}\n",
        "\"\"\"\n",
        "#Create a chunk parser\n",
        "chunk_parser = RegexpParser(chunk_patterns)\n",
        "result = chunk_parser.parse(pos_tags)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0iyd2rJSvE",
        "outputId": "0ab3919d-5bc6-47f6-ad13-b5411b5b0c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP Natural/JJ language/NN)\n",
            "  (NP processing/NN)\n",
            "  (/(\n",
            "  NLP/NNP\n",
            "  )/)\n",
            "  (VP is/VBZ (NP the/DT science/NN))\n",
            "  of/IN\n",
            "  getting/VBG\n",
            "  computers/NNS\n",
            "  to/TO\n",
            "  talk/VB\n",
            "  ,/,\n",
            "  or/CC\n",
            "  (NP interact/NN)\n",
            "  with/IN\n",
            "  humans/NNS\n",
            "  in/IN\n",
            "  (NP human/JJ language/NN)\n",
            "  ./.\n",
            "  Examples/NNS\n",
            "  of/IN\n",
            "  (NP natural/JJ language/NN)\n",
            "  (NP processing/NN)\n",
            "  (VP include/VBP (NP speech/JJ recognition/NN))\n",
            "  ,/,\n",
            "  spell/RB\n",
            "  check/VB\n",
            "  ,/,\n",
            "  autocomplete/VB\n",
            "  ,/,\n",
            "  chatbots/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  (NP search/NN)\n",
            "  engines/NNS\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.draw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "uMs2vcdcKx1_",
        "outputId": "4277915d-6789-4c3b-dc2b-b5d1e04f7197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Tree.draw of Tree('S', [Tree('NP', [('Natural', 'JJ'), ('language', 'NN')]), Tree('NP', [('processing', 'NN')]), ('(', '('), ('NLP', 'NNP'), (')', ')'), Tree('VP', [('is', 'VBZ'), Tree('NP', [('the', 'DT'), ('science', 'NN')])]), ('of', 'IN'), ('getting', 'VBG'), ('computers', 'NNS'), ('to', 'TO'), ('talk', 'VB'), (',', ','), ('or', 'CC'), Tree('NP', [('interact', 'NN')]), ('with', 'IN'), ('humans', 'NNS'), ('in', 'IN'), Tree('NP', [('human', 'JJ'), ('language', 'NN')]), ('.', '.'), ('Examples', 'NNS'), ('of', 'IN'), Tree('NP', [('natural', 'JJ'), ('language', 'NN')]), Tree('NP', [('processing', 'NN')]), Tree('VP', [('include', 'VBP'), Tree('NP', [('speech', 'JJ'), ('recognition', 'NN')])]), (',', ','), ('spell', 'RB'), ('check', 'VB'), (',', ','), ('autocomplete', 'VB'), (',', ','), ('chatbots', 'NNS'), (',', ','), ('and', 'CC'), Tree('NP', [('search', 'NN')]), ('engines', 'NNS'), ('.', '.')])>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.tree.tree.Tree.draw</b><br/>def draw()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/nltk/tree/tree.py</a>Open a new window containing a graphical diagram of this tree.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 755);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJkOBzI2XPq0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}